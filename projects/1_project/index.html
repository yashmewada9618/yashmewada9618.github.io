<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Structure From Motion | Yash R. Mewada</title>
    <meta name="author" content="Yash R. Mewada">
    <meta name="description" content="3D reconstruction based on sequence of images">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%99%82&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yashmewada9618.github.io/projects/1_project/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yash </span>R. Mewada</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Structure From Motion</h1>
            <p class="post-description">3D reconstruction based on sequence of images</p>
          </header>

          <article>
            <p><a href="https://github.com/yashmewada9618/Structure-From-Motion-by-factorization" rel="external nofollow noopener" target="_blank">GitHub</a> <br>
This project details a novel approach for Structure from Motion based on optical flow and factorization for the reconstruction of surfaces with few textures. 
An original image search and grouping strategy allows to the reconstruction of each 3D scene point using a large set of 2D homologous points extracted from a reference image
and its superimposed images acquired from different viewpoints. <br>
Factorization method based on cholensky decomposition was used here. The feautes were detected using SIFT feature detection. <br>
After these features were detected the <strong>Spare Optical Flow</strong> was used to track these features over the images. <br>
<strong>Spare Optical Flow</strong> - Let’s assume you have a pixel with intensity function as $I(x,y,t)$ where x,y is the pixel coordinate and t is the time frame. Now after a certain amount of time, the pixel intensity shifted to a new location, then the new location of this pixel intensity will be equal to…
\begin{equation}
    I(x,y,t) = I(x + \Delta x,y + \Delta y,t + \Delta t)
\end{equation}
Using Taylor series expansion we can rewrite the equation as. <br>
\begin{equation}
    I(x,y,t) - I(x + \Delta x,y + \Delta y,t + \Delta t) = 0
\end{equation}
\begin{equation}
    I_x^{‘} u + I_y^{‘} v = -I_t^{‘}
\end{equation} <br>
Where \(u = \frac{dx}{dt}\) and \(v = \frac{dy}{dt}\)
Hence the pixel motion between two consecutive frames can be written as.
\begin{equation}
    I_1 - I_2 \approx I_x^{‘} u + I_y^{‘} v + I_t^{‘}
\end{equation}</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        

<figure>

  

  <video src="/assets/video/sfm.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""></video>

  

</figure>

    </div>
</div>

<p>The above implementation has some below limitations. \</p>
<ol>
  <li>Accumulation of errors.
    <ul>
      <li>Optical flow methods estimate motion locally on a per-pixel basis, and errors in pixel-level motion estimates can accumulate over time, leading to drift in the reconstructed 3D structure.</li>
    </ul>
  </li>
  <li>No Global Consistency:
    <ul>
      <li>Optical flow lacks global consistency across frames, making it challenging to ensure that the reconstructed 3D structure maintains accuracy and coherence over time.</li>
    </ul>
  </li>
</ol>

<p>Bundle Adjustment (BA) solves these errors and performs global optimization.</p>

<h1 id="a-brief-note-on-bundle-adjustment">A brief note on Bundle Adjustment.</h1>
<p>BA is a non-linear method for solving the problem of simultaneously refining a set of initial camera and 3D scene parameters, so that the projected 3D points are as close as possible to the observed 2D points. The goal is to minimize the reprojection error. The reprojection error is the difference between the projected 3D points and the observed 2D points. The reprojection error is minimized using Levenberg-Marquardt algorithm. The reprojection error is given by:</p>

<p>\begin{equation}
    \epsilon = \sum_{i=1}^{N} \sum_{j=1}^{M} \left| \mathbf{u}_{ij} - \pi \left( \mathbf{P}_i \mathbf{X}_j \right) \right|^2
\end{equation}</p>

<p>, where \(\mathbf{u}_{ij}\) is the \(j^{th}\) observed 2D point in the \(i^{th}\) image, \(\mathbf{P}_i\) is the camera matrix of the \(i^{th}\) image and \(\mathbf{X}_j\) is the \(j^{th}\) 3D point. \(\pi\) is the projection function which projects the 3D point to the image plane. The projection function is given by:</p>

<p>\begin{equation}
    \pi \left( \mathbf{P}<em>i \mathbf{X}_j \right) = \frac{1}{\mathbf{P}</em>{i_{3}} \mathbf{X}<em>{j</em>{3}}} \begin{bmatrix} \mathbf{P}<em>{i</em>{1}} \mathbf{X}<em>{j</em>{1}} \ \mathbf{P}<em>{i</em>{2}} \mathbf{X}<em>{j</em>{2}} \end{bmatrix}
\end{equation}</p>

<p>Now the measurement variable \(\mathbf{z}\) is given by:</p>

<p>\begin{equation}
    \mathbf{z} = h \left( \mathbf{u}_{ij}, \mathbf{X}_j \right) 
\end{equation}</p>

<p>, where \(h\) is the measurement function which is given by:</p>

<p>\begin{equation}
    h (\mathbf{u_{ij}}, \mathbf{X_j}) = \mathbf{u_{ij}} - \pi( \mathbf{P_i} \mathbf{X_j} )
\end{equation}</p>

<p>Furthermore, the Jacobian of the measurement function is given by:</p>

<p>\begin{equation}
    \mathbf{H} = 
    \begin{bmatrix} 
        \frac{\partial h_1}{\partial \mathbf{P}_i} &amp; \frac{\partial h_1}{\partial \mathbf{X}_j} <br>
        \frac{\partial h_2}{\partial \mathbf{P}_i} &amp; \frac{\partial h_2}{\partial \mathbf{X}_j}
    \end{bmatrix}
\end{equation}</p>

<p>The error function is given by:</p>

<p>\begin{equation}
    \mathbf{e} = \mathbf{z} - h \left( \mathbf{u}_{ij}, \mathbf{X}_j \right)
\end{equation}</p>

<p>The main idea is to minimize this error function which is a non-linear function. We can use any other non-linear optimization methods like Guass-Newton, Levenberg-Marquardt, etc. I have used Levenberg-Marquardt algorithm provided by the GTSAM library. For this specific problem there are two Jacobians formed, which are nothing but the partial derivatives of the poses and landmarks. The Jacobian of the poses is given by:</p>

<p>\begin{equation}
    \frac{\partial \mathbf{e}}{\partial \mathbf{P}_i} = \frac{\partial \mathbf{e}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{P}_i} = - \frac{\partial \mathbf{e}}{\partial \mathbf{z}} \frac{\partial h}{\partial \mathbf{P}_i}
\end{equation}</p>

<p>The Jacobian of the landmarks is given by:</p>

<p>\begin{equation}
    \frac{\partial \mathbf{e}}{\partial \mathbf{X}_j} = \frac{\partial \mathbf{e}}{\partial \mathbf{z}} \frac{\partial \mathbf{z}}{\partial \mathbf{X}_j} = - \frac{\partial \mathbf{e}}{\partial \mathbf{z}} \frac{\partial h}{\partial \mathbf{X}_j}
\end{equation}</p>

<p>We combine the Jacobians of the poses and landmarks to form the Hessian Matrix used in either Guass-Newton or Levenberg-Marquardt algorithm. The Hessian Matrix is given by:</p>

<p>\begin{equation}
    \mathbf{H} = \mathbf{J}^T \mathbf{J}
\end{equation}</p>

<p>, where \(\mathbf{J}\) is the Jacobian matrix. The Jacobian matrix is given by:</p>

<p>\begin{equation}
    \mathbf{J} = \begin{bmatrix} \frac{\partial \mathbf{e}}{\partial \mathbf{P}_1} &amp; \frac{\partial \mathbf{e}}{\partial \mathbf{P}_2} &amp; \cdots &amp; \frac{\partial \mathbf{e}}{\partial \mathbf{P}_N} &amp; \frac{\partial \mathbf{e}}{\partial \mathbf{X}_1} &amp; \frac{\partial \mathbf{e}}{\partial \mathbf{X}_2} &amp; \cdots &amp; \frac{\partial \mathbf{e}}{\partial \mathbf{X}_M} \end{bmatrix}
\end{equation}</p>

<p>Dealing with this Hessian matrix is computationally expensive, as even for small number of poses this matrix can get dense. So we use the Schur Complement to reduce the size of the Hessian matrix or basically make it sparse in a way without loosing any information.</p>

<p>Read more about Bundle Adjustment <a href="https://www.cs.cmu.edu/~kaess/vslam_cvpr14/media/VSLAM-Tutorial-CVPR14-A13-BundleAdjustment.pdf" rel="external nofollow noopener" target="_blank">here</a>.</p>

<p>This repo contains the code for the above mentioned title. As it was difficult to write and visualise the results in <code class="language-plaintext highlighter-rouge">.ipynb</code> file, the complete working code is written in the <a href="https://gitlab.com/mewada.y/eece7150/-/blob/main/HW5/Scripts/main.py?ref_type=heads" rel="external nofollow noopener" target="_blank">main.py</a> file. Below is the output I got using bundle adjustment. The 3D structure somewhat resembles that of Buddha. The optimizer tried to minimize the reprojection error upto 420 pixels which is still more as the 3D points are scaled.</p>

<h1 id="output">Output</h1>

<div class="row">
  <div class="column">
    <img src="/assets/img/BA.png" alt="After_BA" width="700">
  </div>
  <div class="column">
    <img src="/assets/img/compare.png" alt="Comparision" width="700">
  </div>
  <div class="column">
    <img src="/assets/img/CameraPosesComparision.png" alt="Camposes" width="700">
  </div>
</div>

<h1 id="how-3d-points-are-obtained-in-this-code">How 3D points are obtained in this code?</h1>
<p>So the steps follwed for creating the 3D points are as follows:</p>
<ol>
  <li>For first pair of images the 3D point cloud is initialised.
    <ul>
      <li>The keypoints are obtained using SIFT with <code class="language-plaintext highlighter-rouge">nfeatures=5000</code> and <code class="language-plaintext highlighter-rouge">nOctaveLayers=3</code>.</li>
      <li>The matches are obtained using <code class="language-plaintext highlighter-rouge">cv2.FlannBasedMatcher()</code>.</li>
      <li>The matches are filtered using <code class="language-plaintext highlighter-rouge">cv2.RANSAC</code> and <code class="language-plaintext highlighter-rouge">cv2.findEssentialMat()</code>.</li>
      <li>The camera pose is obtained using <code class="language-plaintext highlighter-rouge">cv2.recoverPose()</code>.</li>
      <li>The 3D points are obtained using <code class="language-plaintext highlighter-rouge">cv2.triangulatePoints()</code>.</li>
      <li>A dictionary and a class object for 3d points had been maintained throughout the code, where for every 3D point its corresponding 2D points in which it is visible is stored.</li>
    </ul>
  </li>
  <li>For the next pair of images, the 3D points are obtained as follows:
    <ul>
      <li>The keypoints are obtained using SIFT with <code class="language-plaintext highlighter-rouge">nfeatures=5000</code> and <code class="language-plaintext highlighter-rouge">nOctaveLayers=3</code>.</li>
      <li>The matches are obtained using <code class="language-plaintext highlighter-rouge">cv2.FlannBasedMatcher()</code>.</li>
      <li>The matches are filtered using <code class="language-plaintext highlighter-rouge">cv2.RANSAC</code>.</li>
      <li>Then an exhaustive search is performed to find if the filtered keypoints where previously in the dictionary or not, if not then it is added to the    dictionary. If it was in the dictionary then its corresponding 3D point and its index is obtained.</li>
      <li>The new keypoints are again filtered based on the found matched points from the dictionary.</li>
      <li>Those points are used to obtain the relative Camera poses and this time <code class="language-plaintext highlighter-rouge">cv2.solvePnPRansac()</code>
</li>
      <li>For the obtained rotation and translation, the 3D points are triangulated using <code class="language-plaintext highlighter-rouge">cv2.triangulatePoints()</code>.</li>
      <li>The new 3D points are added to the dictionary and the corresponding 2D points are added to the class object, after checking if the 3D point is already in the dictionary or not.</li>
    </ul>
  </li>
  <li>The above steps are repeated for all the pairs of images. And finally Bundle Adjustment is performed using <code class="language-plaintext highlighter-rouge">gtsam</code> library.</li>
</ol>

<p>The graph optimization was able to reduce the pixel reprojection error from 1400 to 600 pixels, which is still more. The reason for this is that the 3D points are scaled. The 3D points are scaled because the camera poses are obtained using <code class="language-plaintext highlighter-rouge">cv2.solvePnPRansac()</code> which gives the camera pose upto a scale factor. So the 3D points are scaled. The graph optimization tries to minimize the reprojection error by adjusting the camera poses and the 3D points. But as the 3D points are scaled, the optimizer is not able to reduce the reprojection error below 600 pixels.</p>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Yash R. Mewada. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
